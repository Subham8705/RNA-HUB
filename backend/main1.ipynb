{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-21T06:26:24.974508Z",
     "start_time": "2025-06-21T06:26:24.969824Z"
    }
   },
   "source": [
    "#data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# performance metrics\n",
    "from sklearn.metrics import f1_score,precision_score, recall_score,make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Model Selection\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Decomposition\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T05:26:52.302832Z",
     "start_time": "2025-06-21T05:26:50.053488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "labels = pd.read_csv('labels.csv')\n",
    "\n",
    "# Rename columns to ensure the keys match\n",
    "data.rename(columns={data.columns[0]: \"sample_id\"}, inplace=True)\n",
    "labels.rename(columns={labels.columns[0]: \"sample_id\"}, inplace=True)\n",
    "\n",
    "# Merge on sample_id\n",
    "cancer_data = pd.merge(data, labels, on='sample_id')\n",
    "\n",
    "# View result\n",
    "print(cancer_data.head())"
   ],
   "id": "6869c08fdb5e51a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample_id  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
      "0  sample_0     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
      "1  sample_1     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
      "2  sample_2     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
      "3  sample_3     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
      "4  sample_4     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
      "\n",
      "     gene_6    gene_7  gene_8  ...  gene_20522  gene_20523  gene_20524  \\\n",
      "0  7.175175  0.591871     0.0  ...    8.210257    9.723516    7.220030   \n",
      "1  6.816049  0.000000     0.0  ...    7.323865    9.740931    6.256586   \n",
      "2  6.972130  0.452595     0.0  ...    8.127123   10.908640    5.401607   \n",
      "3  7.843375  0.434882     0.0  ...    8.792959   10.141520    8.942805   \n",
      "4  6.566967  0.360982     0.0  ...    8.891425   10.373790    7.181162   \n",
      "\n",
      "   gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  gene_20530  \\\n",
      "0    9.119813   12.003135    9.650743    8.921326    5.286759         0.0   \n",
      "1    8.381612   12.674552   10.517059    9.397854    2.094168         0.0   \n",
      "2    9.911597    9.045255    9.788359   10.090470    1.683023         0.0   \n",
      "3    9.601208   11.392682    9.694814    9.684365    3.292001         0.0   \n",
      "4    9.846910   11.922439    9.217749    9.461191    5.110372         0.0   \n",
      "\n",
      "   Class  \n",
      "0   PRAD  \n",
      "1   LUAD  \n",
      "2   PRAD  \n",
      "3   PRAD  \n",
      "4   BRCA  \n",
      "\n",
      "[5 rows x 20533 columns]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T05:28:33.896907Z",
     "start_time": "2025-06-21T05:28:33.659431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Feature and Target Separation\n",
    "X = cancer_data.drop(['sample_id', 'Class'], axis=1)\n",
    "y = cancer_data['Class']\n",
    "\n",
    "# Step 4: Label Encoding\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Step 5: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "id": "eafb53788a463b4c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T06:20:25.481046Z",
     "start_time": "2025-06-21T06:20:22.489494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pca = PCA(n_components=0.95)  # Keep components explaining 95% of variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"Number of PCA components: {X_pca.shape[1]}\")\n",
    "\n",
    "# Step 6: Train-Test Split (create a holdout set)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X_pca, y_encoded, test_size=0.1, random_state=42, stratify=y_encoded\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")"
   ],
   "id": "cf2f69673a18486d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA components: 530\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T05:29:03.222046Z",
     "start_time": "2025-06-21T05:29:03.218220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total"
   ],
   "id": "d8b5dc1ed28c1813",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T06:27:06.566253Z",
     "start_time": "2025-06-21T06:26:32.384292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.3]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy',\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Step 9: Cross-Validation on Training Set\n",
    "cv_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Step 10: Evaluate on Validation Set\n",
    "y_val_pred = best_rf.fit(X_train, y_train).predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=le.classes_))\n",
    "\n",
    "# Step 11: Evaluate on Holdout Set\n",
    "y_holdout_pred = best_rf.predict(X_holdout)\n",
    "holdout_acc = accuracy_score(y_holdout, y_holdout_pred)\n",
    "print(f\"Holdout accuracy: {holdout_acc:.4f}\")\n",
    "print(\"\\nHoldout Classification Report:\")\n",
    "print(classification_report(y_holdout, y_holdout_pred, target_names=le.classes_))"
   ],
   "id": "93dd38de389e2637",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.3, 'max_depth': None}\n",
      "Best cross-validation accuracy: 0.9670164917541229\n",
      "Cross-validation accuracy: 0.9670 ± 0.0186\n",
      "Validation accuracy: 0.9722\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.95      1.00      0.97        54\n",
      "        COAD       1.00      1.00      1.00        14\n",
      "        KIRC       1.00      1.00      1.00        26\n",
      "        LUAD       0.96      0.96      0.96        26\n",
      "        PRAD       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.97       144\n",
      "   macro avg       0.98      0.97      0.97       144\n",
      "weighted avg       0.97      0.97      0.97       144\n",
      "\n",
      "Holdout accuracy: 0.9506\n",
      "\n",
      "Holdout Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        BRCA       0.91      1.00      0.95        30\n",
      "        COAD       1.00      0.88      0.93         8\n",
      "        KIRC       1.00      1.00      1.00        15\n",
      "        LUAD       0.92      0.79      0.85        14\n",
      "        PRAD       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.95        81\n",
      "   macro avg       0.97      0.93      0.95        81\n",
      "weighted avg       0.95      0.95      0.95        81\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T06:28:25.298114Z",
     "start_time": "2025-06-21T06:28:25.203712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 12: Save Model, Scaler, Label Encoder, and PCA\n",
    "import pickle\n",
    "with open(\"rf_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_rf, file)\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as file:\n",
    "    pickle.dump(le, file)\n",
    "with open(\"pca.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pca, file)\n",
    "\n",
    "# Step 13: Feature Importance (if PCA not used, optional)\n",
    "if X_pca.shape[1] == X_scaled.shape[1]:  # If PCA not applied\n",
    "    importances = best_rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(10), importances[indices], align='center')\n",
    "    plt.xticks(range(10), X.columns[indices], rotation=45)\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.show()"
   ],
   "id": "4b8d30471bc0f7b5",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
